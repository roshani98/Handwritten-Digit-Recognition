{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests are objects that flask handles (get set post, etc)\n",
    "from flask import Flask, render_template, request\n",
    "# scientific computing library for saving, reading, and resizing images\n",
    "from scipy.misc import imread, imresize\n",
    "# for matrix math\n",
    "import numpy as np\n",
    "# for regular expressions, saves time dealing with string data\n",
    "import re\n",
    "# system level operations (like loading files)\n",
    "import sys\n",
    "# for reading operating system data\n",
    "import os\n",
    "\n",
    "# tell our app where our saved model is\n",
    "sys.path.append(os.path.abspath(\"./model\"))\n",
    "\n",
    "from load import *\n",
    "\n",
    "# initalize our flask app\n",
    "app = Flask(__name__)\n",
    "# global vars for easy reusability\n",
    "global model, graph\n",
    "# initialize these variables\n",
    "model, graph = init()\n",
    "\n",
    "import base64\n",
    "\n",
    "\n",
    "# decoding an image from base64 into raw representation\n",
    "def convertImage(imgData1):\n",
    "    imgstr = re.search(r'base64,(.*)', str(imgData1)).group(1)\n",
    "    with open('output.png', 'wb') as output:\n",
    "        output.write(base64.b64decode(imgstr))\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "\n",
    "@app.route('/predict/', methods=['GET', 'POST'])\n",
    "def predict():\n",
    "    # whenever the predict method is called, we're going\n",
    "    # to input the user drawn character as an image into the model\n",
    "    # perform inference, and return the classification\n",
    "    # get the raw data format of the image\n",
    "    imgData = request.get_data()\n",
    "    # encode it into a suitable format\n",
    "    convertImage(imgData)\n",
    "    # read the image into memory\n",
    "    x = imread('output.png', mode='L')\n",
    "    # make it the right size\n",
    "    x = imresize(x, (28, 28))\n",
    "    # imsave('final_image.jpg', x)\n",
    "    # convert to a 4D tensor to feed into our model\n",
    "    x = x.reshape(1, 28, 28, 1)\n",
    "    # in our computation graph\n",
    "    with graph.as_default():\n",
    "        # perform the prediction\n",
    "        out = model.predict(x)\n",
    "        print(out)\n",
    "        print(np.argmax(out, axis=1))\n",
    "        # convert the response to a string\n",
    "        response = np.argmax(out, axis=1)\n",
    "        return str(response[0])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # run the app locally on the given port\n",
    "    app.run(host='0.0.0.0', port=5000)\n",
    "# optional if we want to run in debugging mode\n",
    "# app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
